#!/usr/bin/env python3

import argparse
import os
import subprocess as sp
from os.path import (
    join,
    dirname,
    realpath,
    abspath,
    isfile,
    isdir,
    exists,
    splitext,
    basename,
    getsize,
)
import shutil
import time

import btllib

from goldrush_edit_utils import get_random_name, watch_process

SEQ_IDS_FILENAME = "seq_ids"
BF_NAME_TEMPLATE = "targeted_k{}.bf"
BFS_DIRNAME = "targeted_bfs"
BATCH_NAME_INPUT_PIPE = "batch_name_input"
BATCH_TARGET_IDS_INPUT_READY_PIPE = "batch_target_ids_input_ready"
TARGET_IDS_INPUT_PIPE = "target_ids_input"
BFS_READY_PIPE = "bfs_ready"
SEPARATOR = "-"
BATCH_DONE_PIPE = "polishing_done"
GOLDRUSH_EDIT_TARGETED_BFS = "goldrush-edit-targeted-bfs"
GOLDRUSH_EDIT_MAKE = "goldrush-edit-make"

def get_cli_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("seqs_to_polish")
    parser.add_argument("polishing_seqs")
    parser.add_argument("output_seqs")
    parser.add_argument("-k", action="append", default=[])
    parser.add_argument("-t", "--kmer-threshold", type=int, default=5)
    parser.add_argument("-b", "--bsize", default=1, type=int, help="Batch size.")
    parser.add_argument("-m", "--shared-mem", default="/dev/shm")
    parser.add_argument("-v", "--verbose", action="store_true")

    args = parser.parse_args()
    args.seqs_to_polish = abspath(args.seqs_to_polish)
    args.polishing_seqs = abspath(args.polishing_seqs)
    args.output_seqs = abspath(args.output_seqs)
    if len(args.k) == 0:
        args.k = [ 32, 28, 24, 20 ]

    return args


def autoclean(workspace, prefix):
    process = sp.Popen(["goldrush-edit-autoclean", workspace, prefix])
    watch_process(process)


def build_indexes_and_mappings(polishing_seqs_path, seqs_to_polish_path, k_values):
    # Indexes and mapping filenames
    polishing_seqs_index = f"{basename(polishing_seqs_path)}.index"
    seqs_to_polish_index = f"{basename(seqs_to_polish_path)}.index"
    mappings = f"{basename(seqs_to_polish_path)}.mapping.tsv"
    k_values = " ".join(str(k) for k in k_values)

    p = sp.run(
        [
            f""" \
    {GOLDRUSH_EDIT_MAKE} \
    polishing_seqs={polishing_seqs_path} \
    seqs_to_polish={seqs_to_polish_path} \
    K='{k_values}' \
    {seqs_to_polish_index} \
    {mappings} \
    {polishing_seqs_index} \
  """
        ],
        shell=True,
        text=True,
        capture_output=True,
        check=True,
    )
    btllib.log_info(p.stdout + p.stderr)

    return polishing_seqs_index, seqs_to_polish_index, mappings


def run_bf_builder(
    bfs_dir,
    seqs_to_polish,
    seqs_to_polish_index,
    mappings,
    polishing_seqs,
    polishing_seqs_index,
    kmer_threshold,
    batch_name_input_pipe,
    batch_target_ids_input_ready_pipe
):
    process = sp.Popen(
        [
            GOLDRUSH_EDIT_TARGETED_BFS,
            seqs_to_polish,
            seqs_to_polish_index,
            mappings,
            polishing_seqs,
            polishing_seqs_index,
            str(kmer_threshold),
        ],
        cwd=bfs_dir,
    )
    watch_process(process)

    while not exists(batch_name_input_pipe) or not exists(batch_target_ids_input_ready_pipe):
        time.sleep(2)
    btllib.log_info("build_targeted_bfs is ready!")

    return process


def get_next_batch_of_contigs(reader, record_ids, output_filepath, batch_size):
    with btllib.SeqWriter(output_filepath) as tmpwriter:
        reader_done = True
        while record := reader.read():
            tmpwriter.write(record.id, record.comment, record.seq)
            record_ids.append(record.id)
            if record.num % batch_size == batch_size - 1:
                reader_done = False
                break
        return reader_done


def make_tmp_dir(workspace, prefix, suffix):
    tmp_dir = join(workspace, f"{prefix}-{suffix}")
    os.mkdir(tmp_dir)
    return tmp_dir


def polish_batch(
    tmp_dir,
    input_pipepath,
    confirm_pipepath,
    to_polish,
    batch_idx,
    record_ids,
    batch_confirmpipe,
    bfs_dir,
    verbose,
):
    with open(input_pipepath, "w") as f:
        print(batch_idx, file=f)
    with open(confirm_pipepath) as f:
        f.read()

    os.mkfifo(join(tmp_dir, batch_confirmpipe))

    with open(join(tmp_dir, SEQ_IDS_FILENAME), "w") as f:
        for id in record_ids:
            print(id, file=f)

    process = sp.Popen(
        ["polish-batch", to_polish, args.K, str(batch_idx), batch_confirmpipe, bfs_dir]
        + (["--verbose"] if verbose else []),
        cwd=tmp_dir,
    )
    watch_process(process)


def start_reaper():
    # watch process
    pass

def polish_seqs(
    reader,
    seqs_to_polish,
    polishing_seqs,
    k_values,
    kmer_threshold,
    batch_size,
    workspace,
    verbose,
):
    prefix = get_random_name()

    autoclean(workspace, prefix)

    # Build indexes and mappings
    polishing_seqs_index, seqs_to_polish_index, mappings = build_indexes_and_mappings(
        polishing_seqs, seqs_to_polish, k_values
    )

    # Where to build the Bloom filters
    bfs_dir = make_tmp_dir(workspace, prefix, BFS_DIRNAME)

    # Bloom filter names
    bfs = ""
    for k in k_values:
        bf_name = BF_NAME_TEMPLATE.format(k)
        bfs += join(bfs_dir, bf_name) + " "

    # Pipes for communicating with the process building the Bloom filters
    batch_name_input_pipe = join(bfs_dir, BATCH_NAME_INPUT_PIPE)
    batch_target_ids_input_ready_pipe = join(bfs_dir, BATCH_TARGET_IDS_INPUT_READY_PIPE)

    build_targeted_bfs_process = run_bf_builder(
        bfs_dir,
        seqs_to_polish,
        seqs_to_polish_index,
        mappings,
        polishing_seqs,
        polishing_seqs_index,
        kmer_threshold,
        batch_name_input_pipe,
        batch_target_ids_input_ready_pipe
    )

    # Temporary name for the seq(s) to polish
    batch_seqs = "batch.fa"
    last_batch = 0
    batches_done = 0

    start_reaper()

    btllib.log_info("Polishing batches...")
    reader_done = False
    while not reader_done:
        batch_paths.clear()

        for batch_idx in range(batch_size):
            if reader_done:
                break

            record_ids = []

            tmp_dir = make_tmp_dir(polishing_workspace, prefix, batch2_idx)
            batch2_paths.append(tmp_dir)

            reader_done = get_next_batch_of_contigs(
                reader, record_ids, join(tmp_dir, contig_tmppath), batch1_size
            )

            if len(record_ids) > 0:
                polish_batch(
                    tmp_dir,
                    input_pipepath,
                    confirm_pipepath,
                    contig_tmppath,
                    batch2_idx,
                    record_ids,
                    batch2_confirmpipe,
                    bfs_dir,
                    verbose,
                )
            else:
                shutil.rmtree(tmp_dir, ignore_errors=True)
                batch2_paths.pop()

    btllib.log_info("Done polishing batches, ending helper process...")
    with open(input_pipepath, "w") as f:
        print("x", file=f)
    build_targeted_bfs_process.wait()
    shutil.rmtree(bfs_dir, ignore_errors=True)
    btllib.log_info("Polisher done")


if __name__ == "__main__":
    args = get_cli_args()

    # Work in shared memory if possible
    if isdir(args.shared_mem):
        workspace = args.shared_mem
    else:
        workspace = os.getcwd()
        btllib.log_warning(
            f"GoldRush-Edit: {args.shared_mem} not present. Polishing might run slower."
        )

    with btllib.SeqReader(
        args.seqs_to_polish, btllib.SeqReaderFlag.LONG_MODE
    ) as reader:
        polish_seqs(
            reader,
            args.seqs_to_polish,
            args.polishing_seqs,
            args.k,
            args.kmer_threshold,
            args.bsize,
            workspace,
            args.verbose,
        )
