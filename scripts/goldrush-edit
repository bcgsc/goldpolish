#!/usr/bin/env python3

import argparse
import os
import subprocess as sp
from os.path import (
    join,
    dirname,
    realpath,
    abspath,
    isfile,
    isdir,
    exists,
    splitext,
    basename,
    getsize,
)
import shutil
import time

import btllib

from goldrush_edit_utils import get_random_name, watch_process

SEQ_IDS_FILENAME = "seq_ids"
BF_NAME_TEMPLATE = "{}-k{}.bf"
BFS_DIRNAME = "targeted_bfs"
BATCH_NAME_INPUT_PIPE = "batch_name_input"
BATCH_TARGET_IDS_INPUT_READY_PIPE = "batch_target_ids_input_ready"
TARGET_IDS_INPUT_PIPE = "target_ids_input"
BFS_READY_PIPE = "bfs_ready"
BATCH_DONE_PIPE = "polishing_done"
POLISHING_OVER_FILE = "gg"
SEPARATOR = "-"
GOLDRUSH_EDIT_TARGETED_BFS = "goldrush-edit-targeted-bfs"
GOLDRUSH_EDIT_MAKE = "goldrush-edit-make"
GOLDRUSH_EDIT_POLISH_BATCH = "goldrush-edit-polish-batch"
GOLDRUSH_EDIT_REAPER = "goldrush-edit-reaper"
END_SYMBOL = "x"


def get_cli_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("seqs_to_polish")
    parser.add_argument("polishing_seqs")
    parser.add_argument("output_seqs")
    parser.add_argument("-k", action="append", default=[])
    parser.add_argument("-t", "--kmer-threshold", type=int, default=5)
    parser.add_argument("-b", "--bsize", default=1, type=int, help="Batch size.")
    parser.add_argument("-m", "--shared-mem", default="/dev/shm")
    parser.add_argument("-v", "--verbose", action="store_true")

    args = parser.parse_args()
    args.seqs_to_polish = abspath(args.seqs_to_polish)
    args.polishing_seqs = abspath(args.polishing_seqs)
    args.output_seqs = abspath(args.output_seqs)
    if len(args.k) == 0:
        args.k = [32, 28, 24, 20]

    return args


def autoclean(workspace, prefix):
    process = sp.Popen(["goldrush-edit-autoclean", workspace, prefix])
    watch_process(process)


def build_indexes_and_mappings(polishing_seqs_path, seqs_to_polish_path, k_values):
    # Indexes and mapping filenames
    polishing_seqs_index = f"{basename(polishing_seqs_path)}.index"
    seqs_to_polish_index = f"{basename(seqs_to_polish_path)}.index"
    mappings = f"{basename(seqs_to_polish_path)}.mapping.tsv"

    polishing_seqs_index = abspath(polishing_seqs_index)
    seqs_to_polish_index = abspath(seqs_to_polish_index)
    mappings = abspath(mappings)

    k_values = " ".join(str(k) for k in k_values)

    p = sp.run(
        [
            f""" \
    {GOLDRUSH_EDIT_MAKE} \
    polishing_seqs={polishing_seqs_path} \
    seqs_to_polish={seqs_to_polish_path} \
    K='{k_values}' \
    {seqs_to_polish_index} \
    {mappings} \
    {polishing_seqs_index} \
  """
        ],
        shell=True,
        text=True,
        capture_output=True,
        check=True,
    )
    btllib.log_info(p.stdout + p.stderr)

    return polishing_seqs_index, seqs_to_polish_index, mappings


def run_bf_builder(
    bfs_dir,
    seqs_to_polish,
    seqs_to_polish_index,
    mappings,
    polishing_seqs,
    polishing_seqs_index,
    kmer_threshold,
    k_values,
    batch_name_input_pipe,
    batch_target_ids_input_ready_pipe,
):
    k_values = [str(k) for k in k_values]

    process = sp.Popen(
        [
            GOLDRUSH_EDIT_TARGETED_BFS,
            seqs_to_polish,
            seqs_to_polish_index,
            mappings,
            polishing_seqs,
            polishing_seqs_index,
            str(kmer_threshold),
        ]
        + k_values,
        cwd=bfs_dir,
    )
    watch_process(process)

    while not exists(batch_name_input_pipe) or not exists(
        batch_target_ids_input_ready_pipe
    ):
        time.sleep(2)
    btllib.log_info("build_targeted_bfs is ready!")

    return process


def end_bf_builder(batch_name_input_pipe):
    with open(batch_name_input_pipe, "w") as f:
        print(END_SYMBOL, file=f)


def get_next_batch_of_contigs(reader, output_filepath, batch_size):
    with btllib.SeqWriter(output_filepath) as writer:
        seq_ids = []
        reader_done = True
        while record := reader.read():
            writer.write(record.id, record.comment, record.seq)
            seq_ids.append(record.id)
            if record.num % batch_size == batch_size - 1:
                reader_done = False
                break
        return reader_done, seq_ids


def make_tmp_dir(workspace, prefix, suffix):
    tmp_dir = join(workspace, f"{prefix}{SEPARATOR}{suffix}")
    os.mkdir(tmp_dir)
    return tmp_dir


def polish_batch(
    batch_dir,
    batch_name_input_pipe,
    batch_target_ids_input_ready_pipe,
    target_ids_input_pipe,
    bfs_ready_pipe,
    batch_seqs,
    batch_num,
    seq_ids,
    batch_done_pipe,
    bfs_dir,
    k_values,
    verbose,
):
    with open(batch_name_input_pipe, "w") as f:
        print(batch_num, file=f)
    with open(batch_target_ids_input_ready_pipe) as f:
        f.read()

    seq_ids_file = join(batch_dir, SEQ_IDS_FILENAME)
    with open(seq_ids_file, "w") as f:
        for id in seq_ids:
            print(id, file=f)

    # Bloom filter names
    bfs = []
    for k in k_values:
        bf_name = BF_NAME_TEMPLATE.format(batch_num, k)
        bf_path = join(bfs_dir, bf_name)
        bfs.append(f"-b{bf_path}")

    k_values = [f"-k{k}" for k in k_values]

    process = sp.Popen(
        [GOLDRUSH_EDIT_POLISH_BATCH, batch_seqs, bfs_dir]
        + k_values
        + bfs
        + [
            "--seq-ids",
            f"{seq_ids_file}",
            "--bfs-ids-pipe",
            f"{target_ids_input_pipe}",
            "--bfs-ready-pipe",
            f"{bfs_ready_pipe}",
            "--batch-done-pipe",
            f"{batch_done_pipe}",
        ]
        + (["--verbose"] if verbose else []),
        cwd=batch_dir,
    )
    watch_process(process)


def start_reaper(workspace, prefix, batch_polished_seqs, output_seqs):
    process = sp.Popen(
        [GOLDRUSH_EDIT_REAPER, workspace, prefix, batch_polished_seqs, output_seqs]
    )
    watch_process(process)


def create_end_batch(end_file):
    with open(end_file, "w") as f:
        print("1899", file=f)  # :O?!


def confirm_polishing_done(polishing_done_pipepath):
    with open(polishing_done_pipepath, "w") as f:
        f.write(str(1))


def polish_seqs(
    seqs_to_polish,
    polishing_seqs,
    output_seqs,
    k_values,
    kmer_threshold,
    batch_size,
    workspace,
    verbose,
):
    prefix = get_random_name()

    autoclean(workspace, prefix)

    # Build indexes and mappings
    polishing_seqs_index, seqs_to_polish_index, mappings = build_indexes_and_mappings(
        polishing_seqs, seqs_to_polish, k_values
    )

    # Where to build the Bloom filters
    bfs_dir = make_tmp_dir(workspace, prefix, BFS_DIRNAME)

    # Pipes for communicating with the process building the Bloom filters
    batch_name_input_pipe = join(bfs_dir, BATCH_NAME_INPUT_PIPE)
    batch_target_ids_input_ready_pipe = join(bfs_dir, BATCH_TARGET_IDS_INPUT_READY_PIPE)

    build_targeted_bfs_process = run_bf_builder(
        bfs_dir,
        seqs_to_polish,
        seqs_to_polish_index,
        mappings,
        polishing_seqs,
        polishing_seqs_index,
        kmer_threshold,
        k_values,
        batch_name_input_pipe,
        batch_target_ids_input_ready_pipe,
    )

    # Temporary name for the seq(s) to polish
    batch_seqs = "batch.fa"
    batch_polished_seqs = "batch.ntedited.prepd.sealer_scaffold.upper.fa"
    batch_num = 0

    start_reaper(workspace, prefix, batch_polished_seqs, output_seqs)

    btllib.log_info("Polishing batches...")
    reader_done = False
    with btllib.SeqReader(seqs_to_polish, btllib.SeqReaderFlag.LONG_MODE) as reader:
        while not reader_done:
            batch_dir = make_tmp_dir(workspace, prefix, batch_num)

            reader_done, seq_ids = get_next_batch_of_contigs(
                reader, join(batch_dir, batch_seqs), batch_size
            )

            batch_done_pipe = join(batch_dir, BATCH_DONE_PIPE)
            os.mkfifo(batch_done_pipe)

            if batch_num == 1000:
                reader_done = True
                seq_ids = []

            if reader_done:
                assert len(seq_ids) == 0
                polishing_over_file = join(batch_dir, POLISHING_OVER_FILE)
                create_end_batch(polishing_over_file)
                confirm_polishing_done(batch_done_pipe)
            else:
                target_ids_input_pipe = join(
                    bfs_dir, f"{batch_num}{SEPARATOR}{TARGET_IDS_INPUT_PIPE}"
                )
                bfs_ready_pipe = join(
                    bfs_dir, f"{batch_num}{SEPARATOR}{BFS_READY_PIPE}"
                )

                polish_batch(
                    batch_dir,
                    batch_name_input_pipe,
                    batch_target_ids_input_ready_pipe,
                    target_ids_input_pipe,
                    bfs_ready_pipe,
                    batch_seqs,
                    batch_num,
                    seq_ids,
                    batch_done_pipe,
                    bfs_dir,
                    k_values,
                    verbose,
                )

            batch_num += 1

    btllib.log_info("Done polishing batches, ending BF builder process...")
    end_bf_builder(batch_name_input_pipe)
    build_targeted_bfs_process.wait()
    shutil.rmtree(bfs_dir, ignore_errors=True)
    btllib.log_info("Polisher done")


if __name__ == "__main__":
    args = get_cli_args()

    # Work in shared memory if possible
    if isdir(args.shared_mem):
        workspace = args.shared_mem
    else:
        workspace = os.getcwd()
        btllib.log_warning(
            f"GoldRush-Edit: {args.shared_mem} not present. Polishing might run slower."
        )

    polish_seqs(
        args.seqs_to_polish,
        args.polishing_seqs,
        args.output_seqs,
        args.k,
        args.kmer_threshold,
        args.bsize,
        workspace,
        args.verbose,
    )
